Next we list the papers that each member read,
along with their summary and critique.

%Table \ref{tab:symbols} gives a list of common symbols we used.
%\begin{table}[htb]
%\begin{center} 
%\begin{tabular}{|l | c | } \hline \hline 
%Symbol & Definition \\ \hline
%$N$ & number of sound-clips \\
%$D$ & average duration of a sound-clip \\
%$k$  & number of classes \\ \hline
%\end{tabular} 
%\end{center} 
%\caption{Symbols and definitions}
%\label{tab:symbols} 
%\end{table} 

%\noindent\fbox{
%\parbox{0.97\textwidth}{FORMAT FOR PAPER SUMMARY (INCLUDE MAIN IDEA, HOW WE CAN USE IT, AND WHAT IS MISSING FROM THE PAPER):

%\medskip

%The first paper was the wavelet paper by Daubechies
%\cite{Daubechies92Ten}
%\begin{itemize*}
%\item {\em Main idea}: instead of using Fourier transform,
%      wavelet basis functions are localized in frequency {\em and} time.
%      It turns out that they fit real signals better,
%      in the sense they need fewer non-zero coefficients to reconstruct
%      them. Thus they achieve better compression.
%\item {\em Use for our project}:
%      it is extremely related to our sound-clip similarity
%      project, because we can use the top few wavelet coefficients
%      to compare two sound clips.
%\item {\em Shortcomings}:
%      The Daubechies wavelets require a wrap-around setting,
%      which may lead to non-intuitive results.
%\end{itemize*}
%}}%endpar%endfbox

\subsection{Papers read by Björn Bebensee}

\subsubsection{Detecting Clusters of Fake Accounts in Online Social Networks}

\paragraph{Main idea:}
As opposed to previous literature which approaches the fake account classification problem on a per-account basis, Xiao, Freeman and Hwa~\cite{xiao2015detecting} suggest a different approach which uses an approach based on clustering instead. They suggest that as more efficient way of identifying a set of spam accounts made by a single spammer, one might classify entire clusters of users to be legitimate or fake instead of single user accounts. Furthermore their approach focuses on identifying and removing fake accounts before they can interact with legitimate users and spam the network so as to prevent damaging the experience of legitimate users. As they want to stop fake accounts as early as possible and only limited information becomes available during registration Xiao et al. focus on these few features which are available at registration time.

The authors divided their machine learning pipeline into three major parts: a cluster builder, a profile featurizer and an account scorer. The cluster builder takes a raw list of accounts and builds clusters of accounts where the clustering criteria can be simple (i.e. share a common feature) or more complex (like $k$-means). These clusters, along with the features needed for the profile featurizer, are then labelled as real or fake. If there are accounts of both groups in one cluster, it is labelled according to a threshold $x$. The featurizer extracts features from the set of accounts in one cluster to find a numerical representation (an \textit{embedding}) which can then be used by the account scorer to score the cluster. The authors test a number of models for the account scorer, specifically logistic regression, random forests and support vector machines.They find that for their use-case random forests perform best, with a recall slightly better than SVMs. Overall the model showed good performance in tests on in-sample data as well as a newer out-of-sample dataset. The authors have sinced deployed it in production at linked in and restricted more than 250,000 accounts.

\paragraph{Use for our project:}
This paper is closely related to the approach we want to take to classify accounts as genuine or as fake. Xiao et al. suggest classifying entire clusters of users rather than single users to leverage similarities between fake accounts. This technique could prove useful for our approach and can be used in combination with features from each user's social graph. It might be possible to cluster users based on graph features such as degree, number of triangles a node is part of and others.

\paragraph{Shortcomings:}

\subsubsection{Botnet detection using graph‐based feature clustering}

\paragraph{Main idea:}
In this paper Chowdhury et al.~\cite{chowdhury2017botnet} explore the use of graph-based features for clustering in computer networks to detect botnets. As much prior literature has focused on flow-based or rule-based detection, the authors suggest using clustering to first identify clusters of suspicious nodes. The authors are using a self-organizing map (SOM) for dimensionality reduction and clustering by assigning each node to a different cluster according to the output of the SOM. The features used for clustering are node in-degree, out-degree, in-degree weight (i.e. how many packets are received), out-degree weight (i.e. number of outgoing packets), clustering coefficient, node betweenness, and eigenvector centrality. Finally they are classifying nodes in each cluster (except the largest as it is unlikely to contain bots) starting from the smallest cluster using their own bot-search algorithm which only requires examination of few nodes for classification.
Chowdhury et al. show that their approach performs better than SVM classification on the CTU-13 dataset (a dataset of botnet traffic) using the same graph features.

\paragraph{Use for our project:}
Although the approach presented in the paper operates on an entirely different set of data, it is very similar to our goal in its nature. The authors want to identify a set of bad actors in a network given interactions between devices and given the network structure. As we are attempting to classify users in a social network according to the structure and topology of the social graph, we aim to use a set of graph-based features, similar to the features used in the paper, to cluster groups of users which we may subsequently classify jointly.

\paragraph{Shortcomings:}
Calculating all given graph features for all nodes in the graph will not scale very well. For the CTU-13 dataset used by the authors the computation took 30 hours on a supercomputer cluster. This is not an acceptable amount of processing power and time to detect social bots in social networks in (near) real-time in order to prevent interactions with real users. However, as the CTU-13 dataset contains much data and information that is not contained or necessary for an application on social graphs, some of the ideas from these paper may still viable in our use-case. Further experimentation is required.

\subsubsection{Aiding the detection of fake accounts in large scale social online services}

\paragraph{Main idea:}
\cite{cao2012aiding}

\paragraph{Use for our project:}

\paragraph{Shortcomings:}

\subsubsection{Social Bots Detection on Mobile Social Networks}

\paragraph{Main idea:}
\cite{binlin2017social}

\paragraph{Use for our project:}

\paragraph{Shortcomings:}

\subsection{Papers read by Nagmat Nazarov}

\subsubsection{Bot Classification for Real-Life Highly Class-Imbalanced Dataset}

\paragraph{Main idea:}
Generally the researches on bot detection is based on particular botnet characteristics, but in this paper the authors develop three generic features to detect different types of bots regardless of their botnet characteristics. Sarah Harun, Tanveer Hossain Bhuiyan, Song Zhang, Hugh Medal and Linkan Bian~\cite{harun2017bot} suggest five classification models based on those features to classify bots from a large, real-life class-imbalanced network dataset. The authors think that the generalized bot detection methods perform better than the botnet specific methods. 
The bot detection methodology is at first filtering out the unnecessary data and then apply feature extractor to the rest of data. Filtering : The authors filter the IPs which never act as a source and remove IPs which perform only single communication with other IP. After that the bots are extracted based on assumptions of bot behavior according to 1) Falling rate of communication frequency, 2) media communication frequency and 3) source bytes per packet for highest communication frequency.  To develop classification models using these features. The supervised learning algorithms like Quadratic discriminant analysis, Gaussian Naïve Bayes, Support Vector Machine, K Nearest neighbor and Random Forest are used. 
\paragraph{Use for our project:}
The classification results are analyzed according to 6 scenarios , as a result Quadratic discriminant analysis and Gaussian Naïve Bayes perform much better than others. These two supervised learning algorithms are closely related to the approach we want to take to classify accounts as bots or nonbot.  
\paragraph{Shortcomings:}

\subsubsection{Towards a language independent Twitter bot detector}

\paragraph{Main idea:}
\cite{lundberg2019towards}

\paragraph{Use for our project:}

\paragraph{Shortcomings:}

\subsubsection{A network topology approach to bot classification}

\paragraph{Main idea:}
\cite{cornelissen2018network}

\paragraph{Use for our project:}

\paragraph{Shortcomings:}
$\ldots$

