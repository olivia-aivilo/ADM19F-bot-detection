Next we list the papers that each member read,
along with their summary and critique.
Table \ref{tab:symbols} gives a list of common symbols we used.

\begin{table}[htb]
\begin{center} 
\begin{tabular}{|l | c | } \hline \hline 
Symbol & Definition \\ \hline
$N$ & number of sound-clips \\
$D$ & average duration of a sound-clip \\
$k$  & number of classes \\ \hline
\end{tabular} 
\end{center} 
\caption{Symbols and definitions}
\label{tab:symbols} 
 \end{table} 

\noindent\fbox{
\parbox{0.97\textwidth}{FORMAT FOR PAPER SUMMARY (INCLUDE MAIN IDEA, HOW WE CAN USE IT, AND WHAT IS MISSING FROM THE PAPER):

\medskip

The first paper was the wavelet paper by Daubechies
\cite{Daubechies92Ten}
\begin{itemize*}
\item {\em Main idea}: instead of using Fourier transform,
      wavelet basis functions are localized in frequency {\em and} time.
      It turns out that they fit real signals better,
      in the sense they need fewer non-zero coefficients to reconstruct
      them. Thus they achieve better compression.
\item {\em Use for our project}:
      it is extremely related to our sound-clip similarity
      project, because we can use the top few wavelet coefficients
      to compare two sound clips.
\item {\em Shortcomings}:
      The Daubechies wavelets require a wrap-around setting,
      which may lead to non-intuitive results.
\end{itemize*}
}}%endpar%endfbox

\subsection{Papers read by Bj√∂rn Bebensee}

\subsubsection{Detecting Clusters of Fake Accounts in Online Social Networks}

\paragraph{Main idea:}
As opposed to previous literature which approaches the fake account classification problem on a per-account basis, Xiao, Freeman and Hwa~\cite{xiao2015detecting} suggest a different approach which uses an approach based on clustering instead. They suggest that as more efficient way of identifying a set of spam accounts made by a single spammer, one might classify entire clusters of users to be legitimate or fake instead of single user accounts. Furthermore their approach focuses on identifying and removing fake accounts before they can interact with legitimate users and spam the network so as to prevent damaging the experience of legitimate users. As they want to stop fake accounts as early as possible and only limited information becomes available during registration Xiao et al. focus on these few features which are available at registration time.

The authors divided their machine learning pipeline into three major parts: a cluster builder, a profile featurizer and an account scorer. The cluster builder takes a raw list of accounts and builds clusters of accounts where the clustering criteria can be simple (i.e. share a common feature) or more complex (like $k$-means). These clusters, along with the features needed for the profile featurizer, are then labelled as real or fake. If there are accounts of both groups in one cluster, it is labelled according to a threshold $x$. The featurizer extracts features from the set of accounts in one cluster to find a numerical representation (an \textit{embedding}) which can then be used by the account scorer to score the cluster. The authors test a number of models for the account scorer, specifically logistic regression, random forests and support vector machines.They find that for their use-case random forests perform best, with a recall slightly better than SVMs. Overall the model showed good performance in tests on in-sample data as well as a newer out-of-sample dataset. The authors have sinced deployed it in production at linked in and restricted more than 250,000 accounts.

\paragraph{Use for our project:}
This paper is closely related to the approach we want to take to classify accounts as genuine or as fake. Xiao et al. suggest classifying entire clusters of users rather than single users to leverage similarities between fake accounts. This technique could prove useful for our approach and can be used in combination with features from each user's social graph. It might be possible to cluster users based on graph features such as degree, number of triangles a node is part of and others.

\paragraph{Shortcomings:}

\subsubsection{Social Bots Detection on Mobile Social Networks}

\paragraph{Main idea:}
\cite{binlin2017social}

\paragraph{Use for our project:}

\paragraph{Shortcomings:}

\subsection{Papers read by Nagmat Nazarov}

$\ldots$

