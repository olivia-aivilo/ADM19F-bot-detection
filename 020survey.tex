In this section we will list papers that each member has read and reviewed as part of a first survey into the topic, along with a summary of their main ideas, how they can be of use for our own approach and possible shortcomings of the approach or important points not addressed by the paper.

%Table \ref{tab:symbols} gives a list of common symbols we used.
%\begin{table}[htb]
%\begin{center} 
%\begin{tabular}{|l | c | } \hline \hline 
%Symbol & Definition \\ \hline
%$N$ & number of sound-clips \\
%$D$ & average duration of a sound-clip \\
%$k$  & number of classes \\ \hline
%\end{tabular} 
%\end{center} 
%\caption{Symbols and definitions}
%\label{tab:symbols}
%\end{table} 

\subsection{Papers read by Björn Bebensee}

\subsubsection{Detecting Clusters of Fake Accounts in Online Social Networks}

\paragraph{Main idea:}
As opposed to previous literature which approaches the fake account classification problem on a per-account basis, Xiao, Freeman and Hwa~\cite{xiao2015detecting} suggest a different approach which uses an approach based on clustering instead. They suggest that as more efficient way of identifying a set of spam accounts made by a single spammer, one might classify entire clusters of users to be legitimate or fake instead of single user accounts. Furthermore their approach focuses on identifying and removing fake accounts before they can interact with legitimate users and spam the network so as to prevent damaging the experience of legitimate users. As they want to stop fake accounts as early as possible and only limited information becomes available during registration Xiao et al. focus on these few features which are available at registration time.

The authors divided their machine learning pipeline into three major parts: a cluster builder, a profile featurizer and an account scorer. The cluster builder takes a raw list of accounts and builds clusters of accounts where the clustering criteria can be simple (i.e. share a common feature) or more complex (like $k$-means). These clusters, along with the features needed for the profile featurizer, are then labelled as real or fake. If there are accounts of both groups in one cluster, it is labelled according to a threshold $x$. The featurizer extracts features from the set of accounts in one cluster to find a numerical representation (an \textit{embedding}) which can then be used by the account scorer to score the cluster. The authors test a number of models for the account scorer, specifically logistic regression, random forests and support vector machines. They find that for their use-case random forests perform best, with a recall slightly better than SVMs. Overall the model showed good performance in tests on in-sample data as well as a newer out-of-sample dataset. The authors have sinced deployed it in production at linked in and restricted more than 250,000 accounts.

\paragraph{Use for our project:}
This paper is closely related to the approach we want to take to classify accounts as genuine or as fake. Xiao et al. suggest classifying entire clusters of users rather than single users to leverage similarities between fake accounts. This technique could prove useful for our approach and can be used in combination with features from each user's social graph. It might be possible to cluster users based on graph features such as degree, number of triangles a node is part of and others.

\paragraph{Shortcomings:}

\subsubsection{Botnet detection using graph‐based feature clustering}

\paragraph{Main idea:}
In this paper Chowdhury et al.~\cite{chowdhury2017botnet} explore the use of graph-based features for clustering in computer networks to detect botnets. As much prior literature has focused on flow-based or rule-based detection, the authors suggest using clustering to first identify clusters of suspicious nodes. The authors are using a self-organizing map (SOM) for dimensionality reduction and clustering by assigning each node to a different cluster according to the output of the SOM. The features used for clustering are node in-degree, out-degree, in-degree weight (i.e. how many packets are received), out-degree weight (i.e. number of outgoing packets), clustering coefficient, node betweenness, and eigenvector centrality. Finally they are classifying nodes in each cluster (except the largest as it is unlikely to contain bots) starting from the smallest cluster using their own bot-search algorithm which only requires examination of few nodes for classification.
Chowdhury et al. show that their approach performs better than SVM classification on the CTU-13 dataset (a dataset of botnet traffic) using the same graph features.

\paragraph{Use for our project:}
Although the approach presented in the paper operates on an entirely different set of data, it is very similar to our goal in its nature. The authors want to identify a set of bad actors in a network given interactions between devices and given the network structure. As we are attempting to classify users in a social network according to the structure and topology of the social graph, we aim to use a set of graph-based features, similar to the features used in the paper, to cluster groups of users which we may subsequently classify jointly.

\paragraph{Shortcomings:}
Calculating all given graph features for all nodes in the graph will not scale very well. For the CTU-13 dataset used by the authors the computation took 30 hours on a supercomputer cluster. This is not an acceptable amount of processing power and time to detect social bots in social networks in (near) real-time in order to prevent interactions with real users. However, as the CTU-13 dataset contains much data and information that is not contained or necessary for an application on social graphs, some of the ideas from these paper may still viable in our use-case. Further experimentation is required.

\subsubsection{Aiding the detection of fake accounts in large scale social online services}

\paragraph{Main idea:}
Cao, Sirivianos, Yang and Pregueiro~\cite{cao2012aiding} build on previous work in \emph{sybil detection} that aims to use random walks to identify fake accounts (\emph{sybils}) based on key observations made on the structure of social graphs. Specifically a main assumption in these fake account detection schemes is that the connectivity between real users and fake accounts is limited and lower than the number of inter-user and inter-bot connections. In this work Cao et al. propose a new algorithm called SybilRank which, unlike previous work in the field, does not aim to make a binary classification of each user account but instead focuses on creating a ranking which allows for a measure of confidence in classifications as well as further challenges like \emph{captchas} for suspicious accounts. The key idea behind this algorithm is that in a social network an early-terminated random walk starting from a real user account has a higher probability of landing at another real-user than at a fake account. Early termination is necessary for these random walks as the probability of landing at any node converges to a uniform distribution for random walks of sufficient length. The authors can thus use the degree-normalized landing probability of early-terminated random walks to rank nodes and leverage the fact that connections between real users and fake accounts are limited. They further propose a more effecient way of calculating the landing probability of random walks using power iteration.


\paragraph{Use for our project:}
Use for our project: Cao et al. show that it is possible to leverage the topology of the social graph, specifically the weak links between fake accounts and real users, to identify these fake accounts. As we plan to use binary classification for this task, it could prove helpful to include the degree-normalized landing probability for random walks as an additional graph feature either in the machine learning algorithm or for clustering of similar nodes, given that it can be computed efficiently enough which may not be the case for large-scale social networks.

\paragraph{Shortcomings:}
The authors suggest running the SybilRank algorithm periodically, i.e. once every month, which would give fake accounts a window of time that is big enough to interact with and impact real users' experience on the social network unlike the approach introduced by Xiao et al.~\cite{xiao2015detecting}.

\subsection{Papers read by Nagmat Nazarov}



\subsubsection{Towards a language independent Twitter bot detector}

\paragraph{Main idea:}
The authors present a language independent approach to classify each single tweet to be either auto generated(AGT) or human-generated(HGT). Jonas Lundberg, Jonas Nordqvist and Mikko Laitinen ~\cite{lundberg2019towards} The AGT classifier consists of 10 tweet properties. They are a) \textit{isreply}, b) \textit{isRetweet}, C) \textit{accountReputation} - number of followers divided by number of friends and followers, d) \textit{hashtagdensity},\textit{urldensity}, \textit{mentiondensity} e) \textit{statusperday} f) \textit{favoritesperday} and g) \textit{devicetype}. 
On this paper rather than evaluating all applicable machine learning algorithms(like on the other papers) they prefered tree-based models since they outperform well. The results are generated by J48 and RandomForest tree-based models.   
\paragraph{Use for our project:}
We may use RandomForest tree-based algorithm for detection of bot accounts on online social platforms, since it performed the best training results(error rate 3.73\text{\%}) on this paper.  
\paragraph{Shortcomings:}





\subsubsection{A network topology approach to bot classification}

\paragraph{Main idea:}
The authors are proposing a Network Topology approach to Bot classification problem on online social media platforms. Nowadays automated social agents, or bots are increasingly becoming problematic on social media platforms. Laurewz A Cornelissen, ~\cite{cornelissen2018network} Richard Barnett, Petrus Schoonwinkel,Brent Eichstadt and Hluma Magodla are proposing that the social network topology of a user would be sufficient to determine whether the user is a automated agent or a human. Using an unsupervised machine learning approach, a detection accuracy rate of 70\text{\%} is reached.
A new specialised approach, using ego-centred network topology as feature vectors for unsupervised machine learning was proposed on this paper. 
\cite{cornelissen2018network}

\paragraph{Use for our project:}
The authors suggest to use centrality graph measure, for example celebrities have high indegree and low outdegree. For instance, celebrities on Twitter tend to have more people following them than they follow themselves. The authors also propose that the bots must have high outdegree but very low indegree, since most people will not follow back. We can use this proposal to distinguish the bots with non bots. ~\cite{cornelissen2018network} 
\paragraph{Shortcomings:}




\subsubsection{Bot Classification for Real-Life Highly Class-Imbalanced Dataset}

\paragraph{Main idea:}
Generally the researches on bot detection is based on particular botnet characteristics, but in this paper the authors develop three generic features to detect different types of bots regardless of their botnet characteristics. Sarah Harun, Tanveer Hossain Bhuiyan, Song Zhang, Hugh Medal and Linkan Bian~\cite{harun2017bot} suggest five classification models based on those features to classify bots from a large, real-life class-imbalanced network dataset. The authors think that the generalized bot detection methods perform better than the botnet specific methods. 
The bot detection methodology is at first filtering out the unnecessary data and then apply feature extractor to the rest of data. Filtering : The authors filter the IPs which never act as a source and remove IPs which perform only single communication with other IP. After that the bots are extracted based on assumptions of bot behavior according to 1) Falling rate of communication frequency, 2) media communication frequency and 3) source bytes per packet for highest communication frequency.  To develop classification models using these features. The supervised learning algorithms like Quadratic discriminant analysis, Gaussian Naïve Bayes, Support Vector Machine, K Nearest neighbor and Random Forest are used. 
\paragraph{Use for our project:}
The classification results are analyzed according to 6 scenarios , as a result Quadratic discriminant analysis and Gaussian Naïve Bayes perform much better than others. These two supervised learning algorithms are closely related to the approach we want to take to classify accounts as bots or nonbot.  
\paragraph{Shortcomings:}
The biggest shortcoming of this paper is that it ignores the passive or less active bots from the  beginning. I think less active bots can be initiated instead of single very active bot. Another shortcoming is that the paper does not take into account passive bots from the beginning, which may harm the real users by the time. 